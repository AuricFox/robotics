\documentclass[12pt]{article}
\usepackage[legalpaper, margin=1in]{geometry}
\usepackage{sectsty}
\usepackage[font={small,it}]{caption}
\usepackage{graphicx}
\graphicspath{ {./} }
\usepackage{natbib}
\setlength{\bibsep}{0.0pt}

\sectionfont{\fontsize{12}{15}\selectfont}
\subsectionfont{\fontsize{12}{15}\selectfont}
\subsubsectionfont{\fontsize{12}{15}\selectfont}

\title{Robots in Agriculture}
\author{Samuel Kitzerow, kitze012@umn.edu}
\date{November 14, 2022}

\begin{document}

\maketitle
% ==============================================================================================*
\section*{Abstract}
Work in agriculture is often hard and physically taxing for human workers. In the U.S., an agricultural worker is 20 times more likely to die from illnesses related to heat stress than the average civilian worker~\cite{tigchelaar2020work}. The use of autonomous robots will help alleviate the burden of planting, maintaining, and harvesting crops. By using deep learning, robots can identify the physical features of crop-bearing plants such as strawberries and distinguish them based on plant type and ripeness~\cite{yu2019fruit}. These crops can then be harvested by robots and transported to a collection point. The end result produces a system capable of maintaining farmland and providing produce while minimizing the risk to human workers. This paper will discuss some of the common problems robots face in agriculture and possible solutions for a successful system based on a survey of other related works. The main problems being explored are navigation and plant detection.

% ==============================================================================================
\section{Introduction}
% The mentioned deep neural network algorithms (such as R-CNN, Fast R-CNN, Faster R-CNN, YOLO and SSD) can only roughly calculate the position of the target using the bounding box; they are unable to accurately extract contour and shape information.
It is estimated that the world population will reach nine billion by the year 2050 yet the labor resources will decrease for agriculture while the population in urban areas will increase~\cite{9096177}. The use of automated robots can help bridge the increasing gap in limited food and labor resources that growing populations need~\cite{zhou2022intelligent}. 

% ==============================================================================================*
\section{Problem Description}
The problem being addressed in this paper is the use of robots to achieve precision agriculture (PA). The goal of PA is to reduce costs while maximizing profits. A robot accomplishes this by substituting for the human workforce and selectively caring for each individual plant. This means spraying each individual plant with pesticides and fertilizers instead of vast areas of farmland. This will reduce operating costs and prevent potentially hazardous chemicals from leaching into the environment. A robot can also selectively harvest crops based on ripeness which will help add to the food supply and shrink the gap in the growing labor shortage.

Some challenges that robots face when addressing this problem are autonomous navigation in an outdoor environment and the identification of crops. Navigation presents an especially difficult issue since an outdoor environment is not restricted by walls or barriers that an indoor environment provides. A robot could wander aimlessly into hazardous areas such as roads or waterways which could lead to its destruction. Therefore, a robot must have a way of knowing its location and how to plan for optimal pathways to its goal destination. Another issue impeding navigation is that vegetation covers vast areas of the farmland which often hides the load-bearing surfaces used by a robot to safely execute certain actions~\cite{1307135}. A robot cannot simply run over the obstacles since collisions with crops or farm animals can result in damaged produce and loss in profits~\cite{madokoro2021prototype}. 

The second challenge that the robot must overcome is identifying certain plants and obstacles. The importance of obstacle avoidance cannot be understated since most of the obstacles in agriculture are plants. Callously running over a vine or plant stem could kill the entire plant. The robot could also become tangled or damaged if certain obstacles are not avoided. Plant detection and identification is crucial for distinguishing between weeds and crops. Many methods employed for plant detection have produced results lacking in accuracy and robustness~\cite{chen2021detecting}.  Other methods used, such as BLOB analysis~\cite{dewi2021blob}, can detect the shape and color of the product; however, natural lighting can affect how the robot interprets the data since the lighting will cause the colors to change in intensity~\cite{wang2022review}. Effective plant detection can also help the robot identify targeted crops and potential orientations needed for harvesting. this is important since many crops, like strawberries and tomatoes, are fragile and can be easily damaged so gentle handling during manipulation is required~\cite{xiong2020autonomous}. These issues need to be overcome because consumers expect quality products and will reject anything that is unripe, rotten, or damaged.

% ==============================================================================================*
\section{Related Work}
% Verdant Robotics, Precision Agriculture
A study conducted by Zu \emph{et al.}~\cite{zu2021detection} investigated the use of Mask R-CNN to aid in the farming of tomatoes. In the study, an RGB camera was mounted to a mobile robot that would traverse a greenhouse day and night. This was to simulate the working conditions of a harvesting robot that would detect and segment mature green tomatoes. A total of 2,240 images were used as a training set for the Mask R-CNN model, 620 were used as a verification set, and 320 images were used as a test set. The program showed great success in detecting and segmenting tomatoes where the fruit was overlapping, and leaf/branch occlusions occurred. Another study by Xiong \emph{et al. }~\cite{xiong2020autonomous} utilized robots to detect and harvest strawberries. They utilized a color-based algorithm to detect strawberries that were ready for harvesting; unfortunately, the results varied, and the success of harvesting ranged from 50.0\% to 97.1\% on the first attempt and 75.0\% to 100.0\% on the second attempt. Other studies conducted by Zhou \emph{et al.}~\cite{zhou2022intelligent} and Dewi \emph{et al.}~\cite{dewi2021blob} also explore the use of RGB cameras paired with deep learning to assist robots in agriculture. Yu \emph{et el.}~\cite{yu2019fruit} investigated the use of Mask R-CNN to detect not only ripe fruits but their picking points as well.

Research done by Lepej \emph{et al.}~\cite{LEPEJ2016160} studied the use of SLAM in complex field environments. A mobile robot was developed so that it could operate in different agricultural environments and pass between crop rows with little or no human intervention. The goal was to have the robot selectively treat plants while removing humans from situations that involved potentially dangerous chemicals. The robot used a Laser Range Finder (LRF) data to perform SLAM. This achieved successful results since the LRF could provide accurate distance information and detect landmarks. Work done by Mahmud \emph{et al.}~\cite{MAHMUD2019488} used a non-dominated sorting genetic algorithm to assist a mobile robot in path planning. The goal of the robot was to minimize travel around a greenhouse and conserve pesticides used to spray affected plants. The mapping of the greenhouse had already been constructed and nodes were added using a probabilistic roadmap (PRM). The multi-objective algorithm would be used for building an optimal path through the greenhouse.

% ==============================================================================================*
\section{Results and Insights}
\subsection{Navigation}
Navigation in an agricultural environment requires that a robot has a strong understanding of its surroundings since the environment it functions in is dynamic. Although the overall layout of a farm or plantation changes on a yearly basis and not on a daily one, there are still other factors to consider. The growth of vegetation and movement of livestock never ends so a robot needs to be able to pivot with such changes in order to prevent damage to itself, crops, or animals. Accurate navigation will also enable the system to efficiently track individual plants in a database so that adequate care can be provided. This helps boost production while minimizing costs and the harmful effects agriculture may have on the earth. Precision farming can be utilized by spraying and fertilizing individual plants with a small amount of material instead of large quantities over a large area of farmland~\cite{LEPEJ2016160}. Other labor-intensive tasks such as killing parasitic weeds and harvesting produce can be mitigated with proper navigational techniques.

One of the challenges for robot navigation is minimizing the total time and distance traveled while maximizing the harvest yield~\cite{MAHMUD2019488}. Farms can span many acres with multiple potential pathways for a robot to take. It could easily take an inefficient path where it loses power and becomes stranded. Another challenge is detecting obstacles or hazards that impede the navigation of a robot. The conditions of the terrain can greatly impact its performance. Wheel-based interactions with compacted or loose soil can affect the power consumption and drain the battery or fuel~\cite{REINA2017124}; thus, the robot may become stranded which could cost farmers valuable time and resources to recover.

\subsubsection{Path Planning}
There are many methods to create planned paths which minimize time and travel distance, however, the algorithm used for path planning in agriculture must also account for other objectives such as the number of turns, harvest yields, and material usage to name a few. Deterministic algorithms like Dijkstra's or Bellman-Ford's algorithm would need to be adapted to handle such criteria~\cite{MAHMUD2019488}. One solution is to use an evolutionary multi-objective optimization (EMO) algorithm such as NSGA-II which resolves multi-objective problems like the ones encountered in agriculture. These objectives can be expressed as:

\begin{equation}
    f: X \rightarrow Y, x \in \Omega
\end{equation}

\noindent Where $\Omega$ is the decision space $(x_1, x_2..,x_n)$ that contains the coordinates of each selected destination~\cite{MAHMUD2019488}. The objective space $Y$ forms a Pareto set or set of optimal solutions generated through an evolutionary process~\cite{zhou2021problem,zitzler2004tutorial}. The multi-objective problem can be defined as:

\begin{equation}
    Minimize \hspace{4mm} F(x) = (f_1(x), f_2(x), ..., f_n(x))
\end{equation}

\noindent In solving the minimization problem, given the decision vectors $x$ and $x'$, $x$ is said to dominate $x'$ if:

\begin{equation}
    f_j(x) < f_j(x') \textit{ for at least one } j \in \{1,..,N\}
\end{equation}

\begin{equation}
    f_i(x) \le f_i(x') \textit{ for all } j \in \{1,..,N\}
\end{equation}

\noindent where $N$ is the number of objectives in the system. If there exists a solution where $f_i(x) = f_i(x')$ for at least one index $i \in \{1,..,N\}$, $x$ is said to weakly dominate $x'$. A solution $x$ is said to be Pareto optimal if there is no solution $x'$ that gives $x' < x$. Pareto optimal is a condition where no individual is better off without making another worse off. $F(x)$ is called the Pareto-optimal objective vector. A set of all Pareto-optimal solutions is called the Pareto-optimal set and the entire set of Pareto-optimal objective vectors is called the Pareto front~\cite{MAHMUD2019488}. A Pareto front contains the set of decisions a robot can make to plan an optimal path. The set of decisions can be generated by factoring in certain objectives, such as maximizing harvest yield and minimizing travel distance, to produce a Pareto set. From this set, a robot can formulate a more informed decision on choosing the most dominant solution which in this case is the optimal path. One thing to note is that an EMO algorithm is naturally stochastic and can produce varying results with each run~\cite{ahmed2013multi}. This does not really create much of a problem so long as the robot can get to its destination in an efficient manner. Formulating such a path for a robot to follow is one thing but it must also have a set of reference points in order to even create a path.

\begin{figure}[h]
\centering
\includegraphics[width=0.90\textwidth]{farmgps.png}
\caption{A Farm with GPS points marking intersections and segments sectioned off based on plant type.}
\label{fig:farm}
\end{figure}

One of the go-to methods for determining points of reference for industrial machines is through GPS which serves as an important tool for precision agriculture~\cite{pandey2021evaluation}. The use of GPS coordinates in conjunction with monitoring the position of a robot can help guide it along generated pathways. A farmer can add a set of GPS coordinates to the robot's knowledge base that corresponds with intersections or points of interest. They can also designate a grid of coordinates for a certain crop (see Figure \ref{fig:farm}). Being able to mark grids allows farmers to assign certain tasks and divert the robot to areas of greater precedence. The robot can then use the GPS coordinates as the main set of reference points and generate a set of sub-points to build a planned path. The sub-points would designate the entry and exit locations of each row of crops. A downside to using GPS is that the GPS coordinates can produce some significant error or null readings due to dead zones~\cite{pandey2021evaluation}. A dual-based receiver for GPS increases the accuracy of the coordinates but does not account for potential dead zones.

\subsubsection{Simultaneous Localization and Mapping}

Simultaneous Localization and Mapping (SLAM) is a promising alternative to using standalone GPS coordinates when assisting robots with navigation. SLAM is the process a robot takes to build a map of its environment and, at the same time, use the map to determine its location~\cite{durrant2006simultaneous, comelli2019evaluation}. A simple form of this concept is wheel-based odometry which relays upon wheel encoders to track the rotation of the wheels of the robot. The rotation measurements are used in conjunction with the robot's motion to determine its location~\cite{yousif2015overview}. One of the biggest problems when using a wheel-based odometry method is wheel slippage which causes measurement errors. These errors accumulate over time and cause the robot's estimated position to drift from its actual position~\cite{yousif2015overview}. This creates a serious problem for any robot operating in agriculture since most of its environment is composed of loose soil and uneven ground which is guaranteed to cause wheel slippage.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{mapPoints.png}
\caption{ORB-SLAM generating points from selected keyframes for mapping an environment.~\cite{mur2015orb}.}
\label{fig:points}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{slam.png}
\caption{Map reconstruction of an environment using ORB-SLAM. The blue (Top) shows the loop closure, the red shows the current area being mapped, and the green shows the trajectory.~\cite{mur2015orb}.}
\label{fig:slam}
\end{figure}

Visual Odometry (VO) offers a solution to localization than wheel-based odometry by estimating the ego-motion of the robot using visual inputs such as a camera~\cite{ciarfuglia2014evaluation, yousif2015overview}. Visual SLAM (vSLAM) uses VO as a building block for vision-based robots that use one or more cameras to reconstruct their environment and make decisions based on perceived features to navigate~\cite{gul2019comprehensive, mur2015orb}. This task is accomplished by collecting corresponding points of scene features (map points) contained in a subset of unique keyframes (see Figure \ref{fig:points}). The keyframes and points need to have an accurate spread of observation points with a significant parallax to satisfy loop closure. These points are used to create edges in the mapping. Eventually, enough keyframes and corresponding points will have been collected over the course of travel so that a full map of the environment can be rendered (see Figure \ref{fig:slam}).

The location of any landmarks is estimated without needing any priori knowledge of the robot's present location. Similar to GPS coordinates, unique landmarks can be placed at intersections or points of interest to help guide the robot from point to point. These landmarks can come in the form of road signs or other distinct objects that do not match the surrounding environment. Think of a bright-colored object or sign plastered with a large number and a white background similar to a speed limit sign. These landmarks act as a point of reference for the robot which can calculate the distance to the landmark, generate a series of intermediate points, and formulate an optimal path; furthermore, the landmarks can be used to train a robot to map its environment. Over time the robot will be able to acquire a knowledge base of its environment and be able to navigate freely.

% ==============================================================================================*
\subsection{Plant and Obstacle Detection}
An important aspect of agriculture is the maintenance of healthy crops. This involves killing weeds, removing diseased plants, fertilizing, and applying pesticides. An experienced farmer can easily determine what is a healthy plant and what needs to be removed, but this task is very labor-intensive and time-consuming. Treating the whole area with pesticides and fertilizer offers a simple fix but at a heavy financial and ecological cost. Vision-based robots can assist farmers with maintaining fields and even harvesting crops, but they need a way to determine the type of plant and any obstacles that may be in the way. 

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{weedDetection.PNG}
\caption{Mask R-CNN used to detect and instantiate different plant species~\cite{valicharla2021weed}.}
\label{fig:weed}
\end{figure}

Mask Region Convolutional Neural Network (Mask R-CNN) offers a solution for crop detection and obstacle avoidance. Mask R-CNN is an extension of Faster R-CNN which is an object detection algorithm that identifies the location of objects within an image~\cite{dollar2017mask, yu2019fruit, chu2021deep}. The main difference between Faster R-CNN and Mask R-CNN is that Mask R-CNN can accurately extract contour and shape information by predicting a segmentation mask in a pixel-to-pixel manner~\cite{dollar2017mask, yu2019fruit}. This is important because it helps the robot determine whether the plant is a crop or a weed based on its unique characteristics (see Figure \ref{fig:weed}). Plants that are categorized as crops can be fertilized and sprayed with pesticides while weeds are sprayed with weed killer or removed. This helps reduce the amount of material needed to maintain a field and reduces the risk of chemicals leaching out into the environment.

\begin{figure}[h!]
\centering
\includegraphics[width=1.0\textwidth]{locStem.PNG}
\caption{Using Mask R-CNN to detect a strawberry and locate the picking point: b. maximum of contour coordinate, c. contour of interest, d. dividing line, e. crop center, f. fruit axis, g. sample A, h. sample B, i. crop center, j. vertex of contour, and k. picking point~\cite{yu2019fruit}}
\label{fig:picking}
\end{figure}

The fruit ripeness and health of the plant can also be detected using Mask R-CNN. Once a ripe crop is detected, Mask R-CNN determines what orientation the robot must take in order to successfully harvest certain crops. Strawberries are particularly sensitive when being harvested and must be plucked at the stem, unlike apples which can be grabbed anywhere on the fruit and picked. The location of the picking point is based on the instance segmentation of the crop in the image. An axis is then determined to identify the growth shape of the target crop. A set of picking points are finally calculated that tells the robot where to pick the targeted crop (see Figure \ref{fig:picking})~\cite{yu2019fruit}. For diseased plants, it is important to identify affected plants at early stages to provide appropriate treatment plans so quality and economic loss can be mitigated~\cite{afzaal2021instance}. Mask R-CNN can identify diseased plants or spoiled produce based on the unique characteristics the plant displays (see Figure \ref{fig:disease}). The robot can then remove the spoiled produce or alert the farmer to areas of potential concern.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{dp6.png}
\caption{Using Mask R-CNN to detect diseased plants and spoiled produce~\cite{afzaal2021instance}}
\label{fig:disease}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{process.png}
\caption{Process of detecting and segmenting tomatoes using Mask R-CNN~\cite{zu2021detection}}
\label{fig:process}
\end{figure}

Mask R-CNN works by evaluating collected images for detection and segmentation. The input image is passed through a set of convolutional layers that abstracts it via the filters and kernels. This extracts the features of the image used to construct a feature map. The feature map is passed through a region proposal network (RPN) built with training data to generate a region of interest (ROI). An ROI align bilinear interpolation is used to compute the targeted regions within the image where corresponding regions in the feature map are pooled to a fixed size in a preselected box. This is also known as the pooling layer where the features in a region are summarized to provide a downsampling of the feature map. Finally, a classification and bounding box regression can be generated and applied to the image. Since Mask R-CNN works on a pixel-to-pixel level, a mask that highlights a region of interest can also be applied to the image. Figure \ref{fig:process} displays an overview of the process.

% ==============================================================================================
\section{Future Work}
% Tactel finger tips


% ==============================================================================================
\section{Conclusion}

\bibliographystyle{plain}
\bibliography{bibliography.bib}

\end{document}